{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling learning systems in artificial and spiking neural networks\n",
    "\n",
    "</br></br>\n",
    "\n",
    "* Author: Jens Egholm Pedersen ``<xtp778@alumni.ku.dk>``\n",
    "* Supervisor: Martin Elsman ``<mael@diku.dk>``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Introduction\n",
    "2. Coding spikes as information\n",
    "3. Domain-specific language: Volr\n",
    "4. Classification experiments\n",
    "5. Findings and reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introduction: Motivation\n",
    "\n",
    "Spiking neural networks (SNN) promising, but\n",
    "* Diverse and non-standard representations\n",
    "* Attempts to learn still not on-par with ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Relatively little attention to information representation\n",
    "* Spill-over from artificial neural networks (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introduction: Hypotheses\n",
    "\n",
    "1. The Volr DSL can translate into spiking and non-spiking neural networks such that the network topologies are retained.\n",
    "2. Using training it is possible for spiking and non-spiking models to solve an MNIST recognition task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. ~~Introduction~~\n",
    "2. Theory: Coding spikes as information\n",
    "3. Domain-specific language: Volr\n",
    "4. Classification experiments\n",
    "5. Findings and reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Theory: Artificial neural networks\n",
    "\n",
    "* Computational graph structures\n",
    "\n",
    "<center>\n",
    "<img src=\"ff.png\" style=\"width:48%\"/>\n",
    "<img src=\"bp.png\" style=\"width:48%\"/>\n",
    "</center>\n",
    "\n",
    "<span style=\"font-size: 70%\">Source: R. Rojas: Neural Networks, Springer 1996</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Theory: Electrical model of a leaky-integrate and fire (LIF) neuron\n",
    "\n",
    "<table>\n",
    "    <tr style=\"background: white\">\n",
    "        <td>$\\frac{dv}{dt} = - {1 \\over \\tau_{c}} (V - J R)$</td>\n",
    "        <td><img src=\"rc.png\" style=\"width: 66%; float: right\"/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Where $V$ is the voltage difference between the inner and outer neuron membranes, $J_M$ is the input charge, $R$ is the leak resistance and $\\tau_{C}$ is the membrane time constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$J_R = {V \\over R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"lif.png\" style=\"width:40%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Theory: LIF activations and parameters\n",
    "\n",
    "<p style=\"font-size:70%\">Input: Constant input current of 2 nA</p>\n",
    "<img src=\"../report/images/membrane.png\" style=\"width: 50%; float:left;\"/>\n",
    "\n",
    "<img src=\"parameters.png\" style=\"width: 48%; float: right;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Theory: Learning in SNN\n",
    "\n",
    "* Feedforward\n",
    "  * Translation of ANN input/output\n",
    "* Backpropagation\n",
    "  * Similar (derivable) activation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Learning: spike rate coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Theory: Coding scheme for SNN\n",
    "\n",
    "Given some activation potential $x$, input current $v$, voltage threshold $V_{thr}$, a max spike rate $r_{max}$, the neuron membrane potential $v$, and some error $\\epsilon$, the neuron spike rate over an interval $t$ is approximately:\n",
    "\n",
    "\\begin{equation}\n",
    "r_i^1(t) = x_i^1 r_{max} {V_{thr} \\over V_{thr} + \\epsilon_i^1 } - {v_i^1(t) \\over t (V_{thr} + \\epsilon_i^1) }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<span style=\"font-size: 70%\">Source: Rueckauer et al., Frontiers in Neuroscience 11:682, 2017.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Theory: Linear translation from current to spike rate\n",
    "\n",
    "<img src=\"../report/images/spike_rate.png\" style=\"width:50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Theory: Composition of  populations\n",
    "\n",
    "$w^l = {0.065 \\over n^{l-1}}, r \\in [0;38]$\n",
    "\n",
    "![](../report/images/spike_rate_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Theory: Spike rate coding and backpropagation\n",
    "\n",
    "* Input coding with linear model\n",
    "* Weight adaptation from ANN to SNN weight parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "* Forward pass in simulator\n",
    "* Backward pass with regular backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. ~~Introduction~~\n",
    "2. ~~Theory: Coding spikes as information~~\n",
    "3. Domain-specific language: Volr\n",
    "4. Classification experiments\n",
    "5. Findings and reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DSL: Use cases\n",
    "\n",
    "* Model plastic neural network structures\n",
    "* Comparable topologies/semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DSL: Requirements\n",
    "1. Semantic consistency\n",
    "  * Between ANN and SNN\n",
    "2. Translation to ANN and SNN\n",
    "3. Learning\n",
    "  * Backpropagation\n",
    "4. Well-typed\n",
    "  * Type checking at compile time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DSL: Expressions\n",
    "\n",
    "Expressions, values and types\n",
    "\n",
    "![](dsl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DSL: Implementation\n",
    "\n",
    "<img src=\"architecture.svg\" style=\"width:35%; float:left;\"/>\n",
    "\n",
    "<img src=\"../report/images/volr-detailed.svg\" style=\"width:25%; margin-left:10%; float: left;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DSL: Tests\n",
    "\n",
    "* Unit tests\n",
    "  * Compiler \n",
    "  * Futhark library\n",
    "  * Python library\n",
    "\n",
    "* Integration tests\n",
    "  * Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### DSL: Example topology test\n",
    "\n",
    "<table style=\"font-size:100%; width:65%\">\n",
    "    <tr><td colspan=2><center>\n",
    "  <code><b>dense</b> 2 4 â¦¶ <b>dense</b> 4 2</code></center></td></tr>\n",
    "    <tr>\n",
    "        <td width=\"70%\" style=\"font-size:60%; vertical-align: top; width=70%;\">\n",
    "<pre style=\"padding:0\">...\n",
    "let x0 = dense (2, 4)\n",
    "let x1 = dense (4, 2)\n",
    "let n = connect_layers x0 x1\n",
    "...\n",
    "</pre>\n",
    "</td>\n",
    "<td style=\"font-size:60%\">\n",
    "<pre style=\"padding:0\">...\n",
    "p1 = Population(2, ...)\n",
    "p3 = Population(4, ...)\n",
    "p5 = Population(2, ...)\n",
    "layer0 = Dense(p1, p3)\n",
    "layer1 = Dense(p3, p5)\n",
    "...\n",
    "</pre>\n",
    "</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. ~~Introduction~~\n",
    "2. ~~Coding spikes as information~~\n",
    "3. ~~Domain-specific language: Volr~~\n",
    "4. Classification experiments\n",
    "5. Findings and reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiment: Experimental setup\n",
    "\n",
    "* Fixed neuron parameters, excitatory weights\n",
    "* 10 experiments with 80/20% training/testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* SNN experiments run twice: \n",
    "  * Random weights\n",
    "  * Weight transfer from Futhark to NEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Experiment: results\n",
    "\n",
    "Accuracies with standard deviations\n",
    "\n",
    "| Task | ANN | SNN w/ random weights | SNN w/ transferred weights | Chance level |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| NAND | 1.000 | 0.370 $\\pm$ 0.040 | 0.69 $\\pm$ 0.216 | 0.75 |\n",
    "| XOR | 1.000 | 0.530 $\\pm$ 0.038 | 0.585 $\\pm$ 0.033 | 0.5 |\n",
    "| Sequential MNIST | 0.710 | 0.147 $\\pm$ 0.044 | 0.098 $\\pm$ 0.006 | 0.1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Experiment: NAND and XOR\n",
    "\n",
    "<table>\n",
    "    <tr><th><center>NAND</center></th><th><center>XOR</center></th></tr>\n",
    "    <tr><td><img src=\"../report/images/nand.png\"/></td>\n",
    "    <td><img src=\"../report/images/xor.png\"/></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Experiment: MNIST\n",
    "\n",
    "\n",
    "<center><img src=\"../report/images/mnist_snn.png\" style=\"width:70%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Experiment: Conclusions\n",
    "\n",
    "<table>\n",
    "    <tr style=\"background-color:white\"><td width=\"40%\">\n",
    "<ul style=\"text-align:left\">\n",
    "    <li>Bad prediction scores</li>\n",
    "    <li style=\"list-style-type:none\">\n",
    "        <ul><li>Imprecise transfer model</li>\n",
    "    <li>Solely excitatory connections</li>\n",
    "    <li>No exploration of hyperparameters</li>\n",
    "        </ul></li>\n",
    "    <li>Learning occurs</li>\n",
    "    <li>Improvement when importing ANN weights</li>\n",
    "    <li>Large number of dead neurons</li>\n",
    "    <li style=\"list-style-type:none\"><ul><li>ReLU model non-differentiable around 0</li></ul></li>\n",
    "        </ul>\n",
    "        </td>\n",
    "        <td>\n",
    "        <img src=\"../report/images/nand.png\"/>\n",
    "        <img src=\"../report/images/xor.png\"/>\n",
    "        </td>\n",
    "        <td><img src=\"../report/images/mnist_snn.png\"/></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. ~~Introduction~~\n",
    "2. ~~Coding spikes as information~~\n",
    "3. ~~Domain-specific language: Volr~~\n",
    "4. ~~Classification experiments~~\n",
    "5. Findings and reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thesis findings\n",
    "\n",
    "<table><tr>\n",
    "    <th>Hypothesis</th><th>Question</th><th>Result</th></tr>\n",
    "    <tr><td rowspan=\"2\">The Volr DSL can translate into spiking and non-spiking neural networks such that the network topologies are retained</td><td>Translation to ANN</td><td>Confirmed</td>\n",
    "    </tr>\n",
    "    <tr><td>Translation to SNN</td><td>Confirmed</td></tr>\n",
    "    <tr>\n",
    "    <td rowspan=\"2\">Using training it is possible for spiking and non-spiking models to solve an MNIST recognition task</td><td>Learning an MNIST task in ANN</td><td>Confirmed</td>\n",
    "    </tr>\n",
    "    <tr><td>Learning an MNIST task in SNN</td><td>Unconfirmed</td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Thesis contributions\n",
    "\n",
    "\n",
    " 1. a domain-specific language for modelling neural network topologies\n",
    " 2. a preliminary model for generalisable learning in SNN\n",
    " 3. a method for transferring optimised non-spiking parameters to SNN"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
