{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelling learning systems in artificial and spiking neural networks\n",
    "\n",
    "</br></br>\n",
    "\n",
    "* Author: Jens Egholm Pedersen ``<xtp778@alumni.ku.dk>``\n",
    "* Supervisor: Martin Elsman ``<mael@diku.dk>``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Presentation agenda\n",
    "\n",
    "1. Introduction\n",
    "2. Coding information in spiking neural networks\n",
    "3. Domain-specific language: Volr\n",
    "4. Classification experiments\n",
    "5. Findings and reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Introduction \n",
    "\n",
    "1. Motivation \n",
    "2. Description\n",
    "3. Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1 Motivation \n",
    "\n",
    "Spiking neural networks (SNN) promising, but\n",
    "* Diverse and non-standard representations\n",
    "* Not much attention to information representation\n",
    "* Spill-over from artificial neural networks (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2 Description\n",
    "\n",
    "* Theoretical\n",
    "  * Investigated coding for SNN\n",
    "  * Backpropagation mechanisms for SNN\n",
    "  * DSL specification\n",
    "* Practical\n",
    "  * Implemented domain-specific language (DSL)\n",
    "  * Implemented machine learning for ANN and SNN\n",
    "  * Performed experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3 Hypotheses\n",
    "\n",
    "1. The Volr DSL can translate into spiking and non-spiking neural networks such that the network topologies are retained.\n",
    "2. Using training it is possible for spiking and non-spiking models to solve an MNIST recognition task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## 2. Neural networks\n",
    "  1. ANN: feedforward and backpropagation\n",
    "  2. SNN: electrical model\n",
    "  2. Coding scheme for SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1 ANN: Feedforward\n",
    "\n",
    "* Computational graph structures\n",
    "\n",
    "<img src=\"ff.png\" style=\"width:48%; float:left\"/>\n",
    "<img src=\"bp.png\" style=\"width:48%; float:right\"/>\n",
    "\n",
    "\n",
    "<span style=\"font-size: 70%\">Source: R. Rojas: Neural Networks, Springer 1996</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1 ANN: Backpropagation\n",
    "\n",
    "* Backpropagation $\\delta$, given an activation function $\\sigma$, weights $w$ and two neuron groups $j$ and $k$:\n",
    "\\begin{equation}\n",
    "  \\delta_j = \\sigma'_j \\sum_k w_{kj} \\delta_k \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1 ANN: Parallel composition\n",
    "\n",
    "* Parallel computational structures\n",
    "\n",
    "<img src=\"ff2.png\" style=\"width:48%; float:left\"/>\n",
    "<img src=\"bp2.png\" style=\"width:48%; float:right\"/>\n",
    "\n",
    "<span style=\"font-size: 70%\">Source: R. Rojas: Neural Networks, Springer 1996</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2 Electrical model of a leaky-integrate and fire (LIF) neuron\n",
    "\n",
    "<table>\n",
    "    <tr style=\"background: white\">\n",
    "        <td>$\\frac{dv}{dt} = - {1 \\over \\tau_{c}} (V - J R)$</td>\n",
    "        <td><img src=\"rc.png\" style=\"width: 66%; float: right\"/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Where $V$ is the voltage difference between the inner and outer neuron membranes, $J_M$ is the input charge, $R$ is the leak resistance and $\\tau_{C}$ is the membrane time constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$J_R = {V \\over R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"lif.png\" style=\"width:40%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2 LIF activations and parameters\n",
    "\n",
    "<p style=\"font-size:70%\">Input: Constant input current of 2 nA</p>\n",
    "<img src=\"../report/images/membrane.png\" style=\"width: 50%; float:left;\"/>\n",
    "\n",
    "<img src=\"parameters.png\" style=\"width: 48%; float: right;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3 Coding scheme for SNN\n",
    "\n",
    "Given some activation potential $x$, input current $v$, voltage threshold $V_{thr}$, a max spike rate $r_{max}$, the neuron membrane potential $v$, and some error $\\epsilon$, the neuron spike rate over an interval $t$ is approximately:\n",
    "\n",
    "\\begin{equation}\n",
    "r_i^1(t) = x_i^1 r_{max} {V_{thr} \\over V_{thr} + \\epsilon_i^1 } - {v_i^1(t) \\over t (V_{thr} + \\epsilon_i^1) }\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "<span style=\"font-size: 70%\">Source: Rueckauer et al., Frontiers in Neuroscience 11:682, 2017.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3 Translation from current to spike rate\n",
    "\n",
    "<img src=\"../report/images/spike_rate.png\" style=\"width:50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3 Composition of  populations\n",
    "\n",
    "$w^l = {0.065 \\over n^{l-1}}, r \\in [0;38]$\n",
    "\n",
    "![](../report/images/spike_rate_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Volr: DSL for neural networks\n",
    "  1. Requirements\n",
    "  2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1 DSL requirements\n",
    "1. Semantic consistency\n",
    "  * Between ANN and SNN\n",
    "2. Translation to ANN and SNN\n",
    "3. Learning\n",
    "  * Backpropagation\n",
    "4. Well-typed\n",
    "  * Type checking at compile time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2 Implementation\n",
    "\n",
    "<img src=\"architecture.svg\" style=\"width:35%; float:left;\"/>\n",
    "\n",
    "<table style=\"font-size:100%; width:65%\">\n",
    "    <tr><td colspan=2><center>\n",
    "  <code><b>dense</b> 2 4 ⦶ <b>dense</b> 4 2</code></center></td></tr>\n",
    "    <tr>\n",
    "        <td width=\"70%\" style=\"font-size:60%; vertical-align: top; width=70%;\">\n",
    "<pre style=\"padding:0\">...\n",
    "let x0 = dense (2, 4)\n",
    "let x1 = dense (4, 2)\n",
    "let n = connect_layers x0 x1\n",
    "...\n",
    "</pre>\n",
    "</td>\n",
    "<td style=\"font-size:60%\">\n",
    "<pre style=\"padding:0\">...\n",
    "p1 = Population(2, ...)\n",
    "p3 = Population(4, ...)\n",
    "p5 = Population(2, ...)\n",
    "layer0 = Dense(p1, p3)\n",
    "layer1 = Dense(p3, p5)\n",
    "...\n",
    "</pre>\n",
    "</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2 Implementation: Parallel\n",
    "\n",
    "<table style=\"font-size:60%\">\n",
    "    <tr><td colspan=2><center><code><b>dense</b> 2 4 ⦶ (<b>dense</b> 4 2 <span style=\"font-size: 110%\">⊖</span> <b>dense</b> 4 2)</code></center></td></tr>\n",
    "    <tr style=\"background-color:white\">\n",
    "        <td style=\"width:50%\">\n",
    "<pre>let x0 = dense (2, 4)\n",
    "</pre>\n",
    "</td><td>\n",
    "<pre>p1 = Population(2, ...)\n",
    "p3 = Population(4, ...)\n",
    "layer0 = Dense(p1, p3)\n",
    "</pre>\n",
    "</td></tr>\n",
    "<tr style=\"background-color:white\"><td style=\"width:50%\">\n",
    "<pre>let x1 = replicate 4\n",
    "let x2 = connect_layers x0 x1\n",
    "</pre>\n",
    "</td><td>\n",
    "<pre>\n",
    "p5 = Population(4, ...)\n",
    "p9 = Population(4, ...)\n",
    "layer3 = Replicate(p3, (p5, p9))\n",
    "</pre>\n",
    "</td></tr>    \n",
    "    <tr style=\"background-color:white\"><td>\n",
    "<pre>let x3 = dense (4, 2) \n",
    "let x4 = dense (4, 2) \n",
    "let x5 = connect_parallel x3 x4\n",
    "let x6 = connect_layers x2 x5\n",
    "</pre>\n",
    "</td><td>\n",
    "<pre>\n",
    "p7 = Population(2, ...)\n",
    "p11 = Population(2, ...)\n",
    "layer1 = Dense(p5, p7)\n",
    "layer2 = Dense(p9, p11)\n",
    "</pre>\n",
    "</td></tr><tr style=\"background-color:white\"><td>\n",
    "<pre>let x7 = merge (2, 2) \n",
    "let x8 = connect_layers x6 x7\n",
    "</pre>\n",
    "</td><td>\n",
    "<pre>p13 = Population(4, ...)\n",
    "layer4 = Merge((p7, p11), p13)\n",
    "</pre>\n",
    "</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Classification experiments\n",
    "\n",
    "1. Experimental setup\n",
    "2. Experimental results\n",
    "3. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.1 Experimental setup\n",
    "\n",
    "* ANN: Futhark on OpenCL\n",
    "* SNN: NEST via PyNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Fixed neuron parameters, excitatory weights\n",
    "* 10 experiments with 80/20% training/testing split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* SNN experiments run twice: \n",
    "  * Random weights\n",
    "  * Weight transfer from Futhark to NEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.1 Experimental results\n",
    "\n",
    "Accuracies with standard deviations\n",
    "\n",
    "| Task | ANN | SNN w/ random weights | SNN w/ transferred weights | Chance level |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| NAND | 1.000 | 0.370 $\\pm$ 0.040 | 0.69 $\\pm$ 0.216 | 0.75 |\n",
    "| XOR | 1.000 | 0.530 $\\pm$ 0.038 | 0.585 $\\pm$ 0.033 | 0.5 |\n",
    "| Sequential MNIST | 0.710 | 0.147 $\\pm$ 0.044 | 0.098 $\\pm$ 0.006 | 0.1 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.2 NAND and XOR: Learning\n",
    "\n",
    "<img src=\"../report/images/nand.png\" style=\"width:47%; float:left; margin: 0;\"/>\n",
    "<img src=\"../report/images/xor.png\" style=\"width:47%; float: left; margin: 0;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.2 MNIST: Learning\n",
    "\n",
    "\n",
    "<center><img src=\"../report/images/mnist_snn.png\" style=\"width:70%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.3 Conclusions\n",
    "\n",
    "* Bad prediction scores\n",
    "  * Imprecise transfer model\n",
    "  * Solely excitatory connections\n",
    "  * No exploration of hyperparameters\n",
    "* Learning occurs\n",
    "* Improvement when importing ANN weights \n",
    "* Large number of dead neurons\n",
    "  * ReLU model non-differentiable around 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Findings and closing remarks\n",
    "  1. Thesis findings\n",
    "  2. Thesis contributions\n",
    "  3. Learning objectives\n",
    "  4. Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.1 Thesis findings\n",
    "\n",
    "<table><tr>\n",
    "    <th>Hypothesis</th><th>Question</th><th>Result</th></tr>\n",
    "    <tr><td rowspan=\"2\">The Volr DSL can translate into spiking and non-spiking neural networks such that the network topologies are retained</td><td>Translation to ANN</td><td>Confirmed</td>\n",
    "    </tr>\n",
    "    <tr><td>Translation to SNN</td><td>Confirmed</td></tr>\n",
    "    <tr>\n",
    "    <td rowspan=\"2\">Using training it is possible for spiking and non-spiking models to solve an MNIST recognition task</td><td>Learning an MNIST task in ANN</td><td>Confirmed</td>\n",
    "    </tr>\n",
    "    <tr><td>Learning an MNIST task in SNN</td><td>Unconfirmed</td></tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.2 Contributions\n",
    "\n",
    "Contributions:\n",
    " 1. a domain-specific language for modelling neural network topologies\n",
    " 2. a preliminary model for generalisable learning in SNN\n",
    " 3. a method for transferring optimised non-spiking parameters to SNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.3 Learning objectives\n",
    "\n",
    "* Survey models for learning through backpropagation in spiking and non-spiking neural networks\n",
    "* Implement backpropagation learning in spiking and non-spiking neural networks\n",
    "* Implement ANNs in the data-parallel functional language Futhark\n",
    "* Implement SNNs in NEST and BrainScaleS\n",
    "* Analyse and compare the SNN model performance through learning rate and accuracy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.4 Reflection\n",
    "\n",
    "* Perform *early* surveys of frameworks\n",
    "* Work needed to explore translation from ANN to SNN\n",
    "  * Excitatory and inhibitory connections\n",
    "* Reuse code\n",
    "  * Optimisers\n",
    "  * Deep learning frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modelling learning systems in artificial and spiking neural networks\n",
    "\n",
    "</br></br>\n",
    "\n",
    "* Author: Jens Egholm Pedersen ``<xtp778@alumni.ku.dk>``\n",
    "* Supervisor: Martin Elsman ``<mael@diku.dk>``"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
