\documentclass[report.tex]{subfiles}
\begin{document}

This thesis sat out to explore \glspl{SNN} and their future relevance to the field of
\gls{ml}.
A \gls{DSL} for neural models was presented, along with two
supporting \gls{ml} libraries for the training of second and third generation
\glspl{NN}. 
To validate that \gls{DSL}, two hypotheses were put forward and experiments were
designed to attempt to falsify these hypotheses.
Finally, a theory for the translation of model parameters for \glspl{SNN} was
developed and tested empirically.

Three experiments, each executed on two different backends, were conducted to
prove two things: that the \gls{DSL} VOLR can translate into second and third
generation neural networks and adapt to a well-known recognition task, using
backpropagation learning.

The experimental results prove that the \gls{DSL} concepts are
translatable between the \gls{NN} paradigms, and that the \gls{DSL} can generate
executable programs that retain the abstract network topologies.

The results further show, that some form of learning was taking place in the
experiments with \glspl{SNN}.
However, flaws in the gradient approximation model and the spike rate coding
scheme, suggests that the model learns consistently wrong patterns and produces a
large quantity of dead neurons.
The experimental results do not disprove that training within \glspl{SNN} is possible,
but further adaptations to the gradient and coding models are required.
\\[0.1cm]

Table \ref{tab:findings} concludes the findings of the thesis:

\def\arraystretch{1.5}
\begin{table}
  \centering
  \begin{tabular}{l c c}
     Hypothesis 1 & Translation to \gls{ANN} & Confirmed \\ \hline
     Hypothesis 1 & Translation to \gls{SNN} & Confirmed \\ \hline
     Hypothesis 2 & Learning an MNIST task in Futhark & Confirmed \\ \hline
     Hypothesis 2 & Learning an MNIST task in NEST & Unconfirmed \\ \hline
  \end{tabular}
  \caption{A summary of the thesis findings.}
  \label{tab:findings}
\end{table}

While this thesis focused on the theoretical foundations of the DSL, its hypotheses were conceived with the assumption that the
technical tools for constructing and simulating spiking neural networks were in place.
During the experimental phase of the project, this assumption proved to be wrong.
For future research, an early benchmark of framework candidates for \gls{DSL} backends
should be part of early initial feasibility studies, to avoid similar obstacles.
For this reason hypothesis 2 could not conclusively be confirmed or disproved.
The corresponding experiment could not be conducted.

Research within \gls{ml}---surrounding \glspl{NN} in particular---offers a large
number of optimisation techniques, which could be employed to improve the above
models.
It is common to operate with a momentum in the learning rate, such that
larger errors cause larger adaptations \cite{Montavon1998, Sutskever2013}.
It is also popular to add a layer normalisation scheme to force the layers to
adhere to a certain property such as a sigmoid distribution.
This could be attempted to avoid the large number of dead neurons, because the
layers can be normalised into a distribution that minimises the likelihood of
zero signals.

In the context of optimisation, the spike rate models are another possibility
for improvement.
The present rate models ignore the amplitude, inter-spike intervals as well as
sub-threshold activity, and are effectively discarding valuable information.
A possible next step can be to explore other coding schemes that
allow for more stable and concise gradient models.

To improve training and learning of the models, alternative paradigms can be explored that do not
rely on differentiability. 
One example is evolution learning, in which the search for optima is more time 
consuming compared to gradient descent, but can be performed without a gradient model.

Another measure to avoid dead neurons is to explore different activation functions. 
The currently used ReLU function\index{ReLU} is flawed in two ways: it is not
differentiable around zero and it does not penalise values close to
zero.
Other activation functions, such as the sigmoid function, or a linear term
that favours larger weights, could disincentivise dead neurons.

The PyNN interface has proven to be less stable and scaleable than anticipated
based on its widespread use and documentation.
However, the architecture of the \gls{DSL} permits a generalise to other
backends, and the Haskell compiler is entirely independent from the experiment
results.
Since the underlying abstract \gls{NN} model stays constant, 
it is possible to compile to other targets such as BrainScaleS or
SpiNNaker.\index{BrainScaleS}
This could also be used to omit the unstable PyNN interface and compile directly
to NEST.

A paper yet to be published by \citeauthor{Tavanaei2019} reviews
techniques for applying deep learning techniques in \glspl{SNN}.
The authors conclude that \glspl{ANN} still perform significantly better than
\glspl{SNN} when it comes to recognition tasks, but that the gap is closing.
Further research on the thesis could include the studies from
\citeauthor{Tavanaei2019} and use them to improve the \gls{DSL}.
\\[0.1cm]

The thesis also picked up on the subject of cognitive science, because the field
is highly invested in the prospects of the simulation of neurophysiology.
Regarding the cognitive REF theory in the context of this thesis, however,
conclusions have to be drawn carefully.
The composition of neural components with a \gls{DSL} are an essential first
step towards being able to not just construct, but also understand, the 
\glspl{NN} models and its semantics.
It is, however, necessary to analyse far bigger and more complex systems before
any connections can be made.
\\[0.1cm]

As a final perspective, there are many merits to the models that seamlessly
compile between platforms, particularly in the context of neuromorphic
computation.
Using a better performing model for the parameter translation, \gls{ANN} models can
be compiled directly to neuromorphic hardware.
Translating functionally complete logical gates (like the NAND gate) into neural
circuits, implies that any logical circuit can be translated.
Tasks like recognition models for faces or objects, as well as algorithmic
problems like sorting, are just a few out many possible applications.
In short, if the accuracies can be improved and translated into neuromorphic hardware, it
would accelerate the current computational capacities of the von Neumann machine
architectures by a factor of at least 100.
\\[0.1cm]

\FloatBarrier

\end{document}
