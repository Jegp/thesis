\documentclass[report.tex]{subfiles}
\begin{document}
This chapter describes the experimental setup that tests the hypotheses
from Section \ref{sec:hypotheses}.
It will begin by describing the assumptions and parameters that underlies the
future simulations, and continue to detail the datasets and methods with which
the hypotheses are tested.

\section{Neuron parameters}
\input{chapters/experiment/parameters}

\section{Parameter translation}
\input{chapters/experiment/translation}

% The Volr DSL can translate into spiking and non-spiking neural networks such that the network topologies are retained.
% Using training it is possible for spiking and non-spiking models to solve an MNIST recognition task.
\section{Problem sets}
A number of problem sets are employed to test the second hypothesis regarding the training of 
spiking and non-spiking models.
First the NAND and XOR logical gates will be trained, as they are simple logic gates
that are often used to validate neural networks.
The NAND and XOR can be expressed as $\neg(A \land B)$ and $\oplus$ respectively.

To solve this problem set the same two different network structures will be built: a sequental
model
\texttt{\textbf{dense} 2 4 $\obar$ \textbf{dense} 4 2} and a parallel model
\texttt{\textbf{dense} (\textbf{dense} 2 2 $\ominus$ \textbf{dense} 2 2) $\obar$ \textbf{dense} 4 2}.
The two networks exists to compare the performance of the parallel structure with 
a traditional sequential one.

The second problem set is the Modified National Institute of Standards and Technology
(MNIST) database\index{MNIST}, which is a famous collection of 60,000 training images
and 10,000 testing images of handwritten digits \cite{LeCun1998}.
The MNIST dataset is a widely used for training neural networks to classify digits (0 - 9),
and are commonly used as implementation benchmarks \cite{Schmidhuber2014, Schmitt2017}.

To solve this problem set a sequential and parallel network will be constructed:
\texttt{\textbf{dense} 100 20 $\obar$ \textbf{dense} 20 10} and
\texttt{(\textbf{dense} 100 10 $\ominus$ \textbf{dense} 100 10) $\obar$ \textbf{dense 20 10}}.

\begin{comment}
\gls{ANN}s have been studied extensively and have surpassed human performance
in a number of tasks (most recently the 
advanced real-time strategy game Starcraft II \cite{DeepMind2019})
\autocite{Schmidhuber2014, Nilsson2009, Russel2007}.
\gls{SNN}s have been studied extensively in smaller applications such as single-neuron studies 
\autocite{Dayan2001, Indiveri2015}, but studies in larger scale are still rare,
although \textcite{Hunsberger2015, Jordan2018, Lin2018, Pfeil2013,
Rueckauer2017, Schmitt2017} have constructed classifiers that reach
near-\gls{ANN} precision, but with a 


\gls{SNN}s have been studied extensively in smaller applications such as single-neuron studies, but less so in larger setups such as learning and classification tasks \autocite{dayan2001, Indiveri2015}.
Conversely \gls{ANN}s have been extensively studied in more complex tasks where architectures such as \gls{DNN} have excelled \autocite{schmidhuber2014, Nilsson2009, russel2007}.

\subsection{Neuromorphic backend} \label{sec:neuromorphic}
% \subsubsection{Experiment stimuli}
% The stimuli describes the ``input'' of the model.
% Such input is defined either as an array of elements directly in the DSL
% or as a reference to a file.

% \subsubsection{Experiment populations}
% The populations describe the topology of the neural network itself.
% As with the stimuli, the populations are built around a block structure that
% contains a number of sub-expressions.

% The \texttt{connection} defines the source stimulus for the population,
% i.e. the population \textit{from} which action-potentials will be forwarded.
% A population can receive stimulus from more than one source.
% The connections are modelled as per the \gls{CSA} described in section
% \ref{sec:volr-csa}.

% % TODO: Describe and invent archetypes... or not?

% \subsubsection{Experiment responses}
% The responses are the ``output'' of the model to be recorded, and can be
% considered as the outcome of the network for training purposes.
% The response block only contains an optional specification of a location for
% the experiment output data.

\end{comment}
\end{document}
