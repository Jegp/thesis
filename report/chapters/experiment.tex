\documentclass[report.tex]{subfiles}
\begin{document}
This chapter describes the experimental setup that aims to validate the
implementation and test the hypotheses
from Section \ref{sec:hypotheses}.
It will begin by describing the assumptions and parameters that underlies the
future simulations, and continue to detail the datasets and methods with which
the hypotheses are tested.

\section{Neuron parameters}
\input{chapters/experiment/parameters}

\section{Parameter translation}
\input{chapters/experiment/translation}

\section{Problem sets}
Three problem sets will be tested: the NAND ($\neg(A \land B)$) and XOR
($\oplus$) logical gates and the 
Modified National Institute of Standards and Technology
(MNIST) database\index{MNIST}.
The NAND and XOR problems are trivial for \glspl{ANN} to learn, and are used as
a means to test and compare the rudimentary learning capacities of the NEST and
BrainScaleS backends.

The NAND and XOR experiments will be based on the same network topology
(\texttt{\textbf{dense} 2 4 $\obar$ \textbf{dense} 4 2}). 
All backends will execute the experiment with randomly initialised weights, but
because the experiments are structurally similar, and because Futhark is
expected to outperform the \glspl{SNN}, the spiking backends will evaluated
a second time with imported weights and biases from previously optimised networks.
The weights and biases from the optimised Futhark will be imported into NEST,
and, after discretising them, the optimised weights and biases from NEST will be
inserted into the BrainScaleS model.
Because of the imprecision in the coding translation scheme between \glspl{ANN} and
\glspl{SNN}, this is expected to improve the performance in the \glspl{SNN} significantly.

The MNIST network will 
\texttt{\textbf{dense} (\textbf{dense} 2 2 $\ominus$ \textbf{dense} 2 2) $\obar$ \textbf{dense} 4 2}.
The two networks exists to compare the performance of the parallel structure with 
a traditional sequential one.

, which is a famous collection of 60,000 training images
and 10,000 testing images of handwritten digits \cite{LeCun1998}.
The MNIST dataset is a widely used for training neural networks to classify digits (0 - 9),
and are commonly used as implementation benchmarks \cite{Schmidhuber2014, Schmitt2017}.

To solve this problem set a sequential and parallel network will be constructed:
\texttt{\textbf{dense} 100 20 $\obar$ \textbf{dense} 20 10} and
\texttt{(\textbf{dense} 100 10 $\ominus$ \textbf{dense} 100 10) $\obar$ \textbf{dense 20 10}}.

\begin{comment}
\gls{ANN}s have been studied extensively and have surpassed human performance
in a number of tasks (most recently the 
advanced real-time strategy game Starcraft II \cite{DeepMind2019})
\autocite{Schmidhuber2014, Nilsson2009, Russel2007}.
\gls{SNN}s have been studied extensively in smaller applications such as single-neuron studies 
\autocite{Dayan2001, Indiveri2015}, but studies in larger scale are still rare,
although \textcite{Hunsberger2015, Jordan2018, Lin2018, Pfeil2013,
Rueckauer2017, Schmitt2017} have constructed classifiers that reach
near-\gls{ANN} precision, but with a 


\gls{SNN}s have been studied extensively in smaller applications such as single-neuron studies, but less so in larger setups such as learning and classification tasks \autocite{dayan2001, Indiveri2015}.
Conversely \gls{ANN}s have been extensively studied in more complex tasks where architectures such as \gls{DNN} have excelled \autocite{schmidhuber2014, Nilsson2009, russel2007}.

\subsection{Neuromorphic backend} \label{sec:neuromorphic}
% \subsubsection{Experiment stimuli}
% The stimuli describes the ``input'' of the model.
% Such input is defined either as an array of elements directly in the DSL
% or as a reference to a file.

% \subsubsection{Experiment populations}
% The populations describe the topology of the neural network itself.
% As with the stimuli, the populations are built around a block structure that
% contains a number of sub-expressions.

% The \texttt{connection} defines the source stimulus for the population,
% i.e. the population \textit{from} which action-potentials will be forwarded.
% A population can receive stimulus from more than one source.
% The connections are modelled as per the \gls{CSA} described in section
% \ref{sec:volr-csa}.

% % TODO: Describe and invent archetypes... or not?

% \subsubsection{Experiment responses}
% The responses are the ``output'' of the model to be recorded, and can be
% considered as the outcome of the network for training purposes.
% The response block only contains an optional specification of a location for
% the experiment output data.

\end{comment}
\end{document}
