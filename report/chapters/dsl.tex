\documentclass[report.tex]{subfiles}
\begin{document}

This first chapter of the thesis motivates and defines
a \gls{DSL} for the modelling of general \gls{NN}s.
The first part of the chapter presents the theory behind second and third
generation \gls{NN}s, so as to posit requirements for the language. 
Finally this chapter will present the \gls{DSL} \index{Volr},
as a means to translate cognitive concepts into computational \gls{NN}
models.

\section{Neural networks} \label{sec:nn}
\Gls{NN}s is a broad term that originates in the neuronal models from
biological brain \cite{Dayan2001}.
The general architecture of neural systems can be explained as circuits
of neurons \index{neuron} connected through weighted edges.
\cite{Russel2007, Dayan2001}.
In this abstract sense a neuron is defined as a computational unit that
takes a number of signals (inputs) and processes them through some
function $f$ that outputs a single value \cite{Eliasmith2004}.
From that perspective neural networks simply \textit{computes} an 
output based on some input why neural networks can be understood as
complex non-linear computations \cite{Eliasmith2004, Dayan2001}.

In a more concrete sense neural networks computes over either
continuous (e. g. voltage and numbers) or discrete signal, and they
can be modelled with or without a temporal dimension
\cite{Eliasmith2004, Russel2007, Schmidhuber2014}.

Discrete models without a temporal dimension were the foundation for
the first generation of neural networks \cite{Russel2007, Maass1997}.
They are based on the perceptron model as seen in equation
\ref{eq:perceptron}, also known as the McCulluch-Pitts neuron model
\cite{Eliasmith2004}.

\begin{equation} \label{eq:perceptron}
f(x) = \begin{cases}
	 1 & \text{if } u > 0\\
	 0 & \text{otherwise}
       \end{cases}
\end{equation}

\subsection{Second generation neural networks}
Second generation neural networks augment the perceptron model by
a) allowing continuous output values of a neuron and b) parametrising
the computation of the neuron by adding an \textit{activation function}
\index{activation function} for when the output ``activates'' 
\cite{Maass1997}.
\textit{Sigmoidal} functions are commonly used for activation functions
because they resemble the perceptron step function while 
retaining continuity (see figure \ref{fig:sigmoid})
\cite{Maass1997}.

\begin{figure}
\centering
\begin{tikzpicture}[domain=-6:6,xscale=0.3]
  \draw[->] (-6.2,0) -- (6.2,0) node[right] {$x$};
  \draw[->] (0,-0.2) -- (0,1.2) node[above] {$\sigma(x)$};
  \draw plot (\x,{1 / (1 + exp(-\x))}) node[right] {$\sigma(x) = {1 \over 1 + e^{-x}}$};
\end{tikzpicture}
\caption{A sigmoidal (soft step) function.}
\label{fig:sigmoid}
\end{figure}

A number of variations for sigmoidal activation functions exist such as the 
hyperbolic tangent ($tanh$) and
the rectified linear unit \index{ReLU} (ReLU, see equation \ref{eq:ReLU}). 
They are applied either in a feed-forward or recurrent (cyclic) manner, where
the recurrent variant are forced to cope with temporal transformations to
terminate\footnote{It is possible to \textit{unfold} recurrent
networks to resemble the circular processes until a certain point, achieving
a similar effect to temporal signal transformation, see \cite{Mozer1995}.}
\cite{Schmidhuber2014}.

\begin{equation} \label{eq:ReLU}
f(x) = \begin{cases}
         0 & \text{if } x < 0 \\
	 x & \text{otherwise}
       \end{cases}
\end{equation}

Second generation neuron models typically enrich the
input signals ($x$) with a weight ($w$) as shown in \ref{eq:weightedsum}
\cite{Schmidhuber2014, Russel2007}. 
Given $n$ input neurons, the weighted sum is the value of each
input neuron ($x_i$) scaled by a weight for that individual neuron ($w_i$).
Weights allow the model to adapt the relative importance of each
input neuron by modifying their weights, thus allowing the
model to \textit{train} to a given domain \cite{Schmidhuber2014, Russel2007}.

\begin{equation} \label{eq:weightedsum}
u = w \cdot x = \sum_{i=1}^n w_i x_i
\end{equation}

For each neuron $j$ the output $x$ can be derived as shown in 
\ref{eq:weightedoutput}.

\begin{equation} \label{eq:weightedoutput}
  x_j = \sigma(u_j) = \sigma(\sum_{i=1}^n w_{i,j} x_i)
\end{equation}

\subsection{Third generation neural networks}
Constructing a network of neuron models essentially creates a non-linear
response to a given numerical vector \cite{Russel2007}.
This transformative view can be adopted to biological \gls{SNN}, where
the data being transferred are no longer vectors, but discrete
\textit{spikes} of electrical current \cite[p. 32]{Dayan2001, Eliasmith2004}.
In this case the activation of a spike can be understood as a function
of the electric current to the neuron cell along with the cell weights,
similar to the weighted sum in equation \ref{eq:weightedsum}
\cite[p. 234]{Dayan2001}.

There is a temporal dimension to this because signals in biological 
networks arrive from multiple sources in parallel \cite{Eliasmith2004}.
Lapicque presented the first model of conductance over time in 1907,
dubbed the \textit{integrate-and-fire} \index{neuron model!integrate-and-fire}
\index{integrate-and-fire|see {neuron model}}
model, because neurons essentially
integrate received current over time to determine whether they should fire 
\cite{Dayan2001, Eliasmith2004}.
The Dirac ($\delta$) function \index{Dirac function}
in equation \ref{eq:dirac} shows an idealised
version of this \cite[p. 404]{Dayan2001}.
For all values it approaches 0, except when its argument is
0 where it will grow infinitely.
The total area of these 'spikes' sum together to 1 over time $t$ \index{neuron spike}.

\begin{equation} \label{eq:dirac}
\int dt\ \delta(t) = 1
\end{equation}

This idealised representation is a common mathematical approximation of
a sequence of activation functions \cite{Dayan2001, Eliasmith2004},
and the foundation for the \textit{third} generation
neural networks, where the computations are understood as spikes over
time \cite{Maass1997}. \index{neuron spike} \index{spike|see {neuron spike}}
In this model the neurons receive a voltage that builds over time, until
it reaches a threshold voltage ($V_{th}$) and produces a single spike
\mbox{($\delta(t-t_n)$)}
\cite{Dayan2001, Eliasmith2004}.
In a brief period after the activation the neuron enters a period of
refraction, \index{refraction period}
where injected voltage is not accumulated, denoted by 
$\tau_{ref}$, illustrated in figure \ref{fig:spiking}
\cite[p. 82]{Eliasmith2004}.

A more realistic neuron model was developed by Hodgkin
and Huxley in 1952 dubbed the Hudgkin-Huxley model \cite{Dayan2001}.
While it is more precise than integrate-and-fire models, it is
more complex \cite[p. 195]{Dayan2001} and rarely used in simulations
\cite{Albada2018, Dayan2001, Eliasmith2015}.

\begin{figure}
\centering

\begin{tikzpicture}[scale=3]
\pgfkeys{/pgf/number format/precision=1}
\draw (0,0) -- (2, 0);
\draw (0,0) -- (0, 1);
\foreach \i in {0,0.2,...,1}
  \draw (0,\i) -- (0.02,\i) node [left] {\scriptsize \pgfmathroundtozerofill{\i}\pgfmathresult};
\foreach \i in {0,20,...,100}
  \draw (\i/50,0) -- (\i/50,0.02) node [below] {\scriptsize \i};

\node [rotate=90] at (-0.25, 0.5) {\text{voltage (V)}};
\node at (1, -0.2) {\text{time (ms)}};

\draw [thick] (0,0) .. controls (12/50,0.50) and (36/50,0.6) .. (67/50, 0.639);
\draw [thick] (67/50,0) -- (67/50,1);
\draw [dashed] (0,0.64) -- (2,0.64) node [right] {\scriptsize $V_{th}$};
\node at (67/50, -0.1) {\scriptsize $t_n$};
\draw [thick] (67/50,0) -- ++ (0.1,0);
\node at (80/50,0.85) {\scriptsize $\delta(t-t_n)$};
\draw [thick] (72/50,0) .. controls (81/50,0.25) and (90/50,0.35) .. (2, 0.42);
\node at (75/50,0.3) {\scriptsize $\tau_{ref}$};
\draw (70/50,0.03) .. controls (71.5/50,0.13) .. (74.5/50,0.24);

\end{tikzpicture}
\caption{A model of the voltage buildup, spiking and refractory period
         of an integrate-and-fire \index{neuron model!integrate-and-fire} 
         neuron with constant current influx.}
\label{fig:spiking}
\end{figure}

Lapicque's model has been elaborated in the \textit{leaky
integrate-and-fire} (LIF) \index{neuron model!leaky-integrate-and-fire}
model, which introduces a numerical ``leak''
into the model, that acts as a type of memory \index{memory}
for the neuron integration \cite{Eliasmith2004, Eliasmith2015}.
Input voltages decays exponentially over time, meaning that the
present voltage depends more strongly on recent input voltages
\cite[p. 86]{Eliasmith2004}.
By controlling the resistance (or leak), it is possible to
control the time with which previous voltages are 'forgotten'
\cite{Eliasmith2004}.

Todo: present 3rd gen NN as a function of previous inputs and weights
% TODO: Present how spike rates are represented
% TODO: Write about noise
%\subsubsection{Neuron spike rates}
%...

%\subsubsection{Encoding and decoding in spiking neural networks}
%...
\begin{comment}
To align digital representations with neural spikes,
signals are encoded and decoded when entering and leaving the system
respectively \cite{Dayan2001}.
Because of the temporal nature of spiking neural networks, probability
distributions are commonly used to describe 
Given a current for background firing rates
Assuming there are $n$ inputs to a neuron with $i$ bits of information,
an encoder
\end{comment}

\subsection{\Gls{NN}s as directed graphs}
Following the above descriptions, \gls{NN}s can be abstracted as a 
directed graph: circuits of computational units connected through
weighted, directed edges \cite{Dayan2001, Eliasmith2004, Russel2007}.
Figure \ref{fig:nn-example} illustrates such a network.
The layered design is typical for first and second generation networks, but 
can be generalised to the third generation as well, despite their parallel
nature.
The second layer is traditionally denoted as `hidden' because it is only
stimulated indirectly \cite{Russel2007}.

\begin{figure}
\centering
\tikzset{%
  every neuron/.style={
    circle, draw, minimum size=0.5cm
  },
  neuron dots/.style={
    draw=none,
    scale=1.5,
    text height=0.3cm,
    execute at begin node=\color{black}$\vdots$
  }
}
\begin{tikzpicture}{x=1.5cm, y=1.5cm}
  \foreach \m [count=\y] in {1,2,dots,n}
    \node [every neuron/.try, neuron \m/.try](input-\m) at (0, 2.5-\y) {};
  \foreach \m [count=\y] in {1, dots, n}
    \node [every neuron/.try, neuron \m/.try](hidden-\m) at (2, 2-\y) {};
  \foreach \m [count=\y] in {1, dots, n}
    \node [every neuron/.try, neuron \m/.try](output-\m) at (4, 2-\y) {};

  \foreach \l [count=\i] in {1, 2, n}
    \draw [<-] (input-\l) -- ++ (-1, 0)
      node [above, midway] {$I_{\l}$};
  \node [above] at (hidden-1.north) {$H_1$};
  \node [below] at (hidden-n.south) {$H_n$};

  \foreach \f in {1, 2, n}
    \foreach \t in {1, n}
      \draw [->] (input-\f) -- (hidden-\t);
  \foreach \f in {1, n}
    \foreach \t in {1, n}
      \draw [->] (hidden-\f) -- (output-\t);
  \foreach \l [count=\i] in {1,n}
    \draw [->] (output-\l) -- ++(1,0)
	node [above, midway] {$O_\l$};

  \foreach \l [count=\x from 0] in {Input, Hidden, Output}
    \node [align=center, above] at (\x*2,2) {\l};
\end{tikzpicture}
\caption{An example neural network with a single hidden layer.}
\label{fig:nn-example}
\end{figure}

In this representation an `input' is a stimulus vector, whose
length is equal to the number of neurons in the first layer.
Conversely, an `output' is a stimulus vector whose length
is controlled by the number of output neurons.
A \gls{NN} can then be understood as a function $f$ that 
maps an input vector to an output vector \cite{Russel2007}.

\section{Learning} \index{learning}
Within the cognitive sciences learning in the context of an \texit{agent} \gls{agent}
refers to ``the process of gaining
information through observation'' \cite{sep:learning-formal}.
Following the above abstraction of neural networks as computations over vectors,
``learning'' in this thesis \index{learning}
refers to the development of consistent patterns, given the same input.
Within the \gls{ml} litterature, this is commonly referred to as 
\textit{predicting} \index{predict} the expected output.
In practice this is expressed in terms of general functions or
\textit{rules} \index{rule} in a network \cite[p. 704.]{Russel2007}.

Within machine learning \gls{ml} three types of
learning exists: supervised, \index{learning!supervised}
unsupervised \index{learning!unsupervised} and reinforced.
\index{learning!reinforcement}

\textit{Supervised} learning relies on a set of expected outputs which 
the learning \gls{agent} must predict, given some input \cite{Russel2007}.
The \gls{agent} is told how `wrong' it was, so it can adapt accordingly.
This learning typically happens in a \textit{training} and \textit{testing}
phase, where the \gls{agent} is allowed to builds its internal representation
which is later tested previously unseen data \cite{Russel2007}.

\textit{Unsupervised} learning asks the \gls{agent} to learn without
having any idea of error margin \cite{Russel2007}.
Rather, the \gls{agent} is asked to \textit{explore} a domain in search of
patterns, which then form the basis for future predictions or classifications
\cite{Russel2007}.

\textit{Reinforced} learning reinforces the \gls{agent} through
rewards and discourages it through punishments \cite{Russel2007}.
Contrary to supervised learning the rewards and punishments are not
instructing the agent on what the output should be, but rather how well
it performed the task, leaving the \gls{agent} to infer rules or
behaviours by itself \cite[p. 873]{Russel2007}.

The process of learning can either be \textit{inductive}
\index{learning!induction}
or \textit{deductive} \index{learning!deduction} \cite[p. 704]{Russel2007}.
The latter requires a basis in rule-based systems from which new knowledge can
be deduced, while the former requires a measurement of success \cite[p. 705]{Russel2007}.
Such a measurement is typically referred to as the \textit{error} or \textit{loss}
function\index{loss function}\index{error function|see {loss function}}
because it shows how much the prediction deviated from the expectation (success)
\cite{Russel2007}.

Learning within neural networks have shown to be possible within all three
types of learning \cite{Schmidhubner2014, Russel2007}, but deduction is rarely
seen in the \gls{NN} literature, because it is cumbersome to express neural
networks through logic transformations 
%TODO: Check citation; write about Eliasmith and DTU logics guy
Because of its simplicity and widespread use, this thesis will focus on supervised
inductive learning.

\subsection{Errors in learning}
It is worth noting that \gls{NN}s may \textit{learn} \index{learn}
rules \index{rule} that are not optimal \cite{Russel2007}.
This can happen in one of two ways: either the
network is structurally incapable of learning the domain, 
or the learned rule is incorrect \cite{Russel2007, Eliasmith2015}.

A \gls{NN} is limited in complexity by its number of nodes,
because one neuron is only capable of describing a binary
outcome \cite{Dayan2001, Russel2007}.
This is sufficient to model a dichotomy, but insufficient
to explain, say, numbers bigger than 1.
Such a structural limit cannot be solved by any other means
than augmenting the network \cite{Russel2007}.

Provided that the network is sufficiently complex, the 
learned rules can still be incorrect.
In inductive processes this is due to a misrepresentation
of data, where the data on which the network bases its
predictions, fails to capture the expectations of the
trainer \cite{Russel2007}.
To avoid this, it is customary to only train the network
on a part of the available data, only to test it on 
the remaining data \cite{Russel2007, Schmidhuber2014}.

\subsection{Backpropagation}

\subsection{Learning in second generation \gls{NN}}
\subsection{Learning in third generation \gls{NN}}

%\subsubsection{Auto-differentiation}
% TODO: Write about autodiff

\section{Similar work}
A vast amount of work has been put into the development of software for simulating
neural networks.
This section covers the most popular and recent projects for both second and third
generation frameworks, and extracts relevant
features for use in the requirements section \ref{sec:requirements}.

\subsection{Second generation software}
The perhaps most notable product for this type of networks is the Tensorflow \index{Tensorflow}
framework \cite{Abadi2016}.
Tensorflow is essentially an infrastructure for the description and execution of directed graph 
structures,
that connects varying activation functions and learning mechanisms through the common abstraction
of tensors \cite{Abadi2015}.
It is a large collaboration of multiple companies and organisations, who have
grown a comprehensive library of both code as well as infrastructure, and they
provide extensive hardware acceleration \cite{Abadi2015}.

The primary advantage of Tensorflow \index{Tensorflow} arrives from 
its foundation in tensors as a general abstraction that
can be applied to a wide array of problems \cite{Abadi2016}.
Other frameworks have adapted a similar approach, such as PyTorch \cite{PyTorch2018}, 
scikit-learn \cite{Sklearn2018}, Microsoft Cognitive Toolkit (CNTK) \cite{CNTK2018},
Caffe \cite{Caffe2018} and Theano \cite{Theano2018}.
The mentioned products differ slightly in terms of syntax and objective\footnote{Especially
PyTorch and Caffe targets \gls{DL}} as well as integrations for data and services, but
all rely on second generation \gls{NN} architecture.

Lasagne and Keras are examples of products that works with higher-level abstractions,
building on Theano and Tensorflow respectively \cite{Lasagne2018, Keras2018}.
They both provide imperative \gls{API}s for constructing models in steps, while
including useful utilities for the molding of data to fit the underlying tensor structures.

In terms of learning the frameworks are diverse, although gradient descent 
and auto-differentiation are among the most common features 
(seen in Tensorflow, PyTorch, CNTK, Theano
and Caffe). 

The Open Neural Network Exchange Format (ONNX) is an open data format for the representation
of \gls{DL} learning models \cite{ONNX2018}. 
In this context ONNX is interesting because it attempts to describe the networks as 
a directed graph, just like Tensorflow.
ONNX is supported by Caffe, CNTK and Pytorch, and translate to Tensorflow,
indicating that a directed graph is 
sufficiently generic to model the structure and learning tasks within 
second generation networks.

\subsection{Third generation software}
The landscape for third generation software is less homogeneous, first and
foremost because the field is still young \cite{Maass1991}.
Secondly there are two different approaches to constructing \gls{SNN}s:
physical or virtual \cite{Maass1997, Davison2009, Albada2018}. %TODO: Check citation

\subsubsection{\Gls{SNN} simulators}
\subsubsection{Neuromorphic hardware}
%PyNN is a simulator-independent

\subsection{Third generation modelling tools}
Before proceeding to the DSL requirements, it is worth introducing
the PyNN \index{PyNN} project \cite{Davison2009}. 
PyNN is a modelling \gls{API} for \gls{Python} that to some degree translates
third generation topologies and physiological descriptors into both simulated
and analogue backends \cite{Davison2009}.
In theory PyNN can target any third generation backend, but has chosen to focus
on projects associated with the \gls{HBP}: NEST, BrainScaleS and SpiNNaker
\index{NEST}\index{BrainScaleS}\index{SpiNNaker}
\cite{Davison2009} %TODO: Check source
It offers decent support for many of the NEST simulation features, but
requires significant amount of programming to post-fit the models to 
run on SpinNaker and BrainScales. %TODO: Add source
This is partly due to the heterogeneous architectures of the backends, but
also because projects such as PyNN faces a difficult trade-off; ease-of-use
versus specificity. %TODO: Add source
PyNN is an attempt to bridge the gap between the vastly different backends
for \gls{SNN}, similar to the Keras and Lasagne projects, but both these
projects have made significant simplifications to broaden their audiences
%TODO: Add source

%TODO: Finish this

\section{DSL requirements} \label{sec:requirements}

% Both types of network are architecturally similar, and both are conceived from
% the same physiological principles \autocite{dayan2001, russel2007, Nilsson2009, schmidhuber2014}.
% The implementations, however, vary greatly.

% To ensure internal and external validity in and between the two network types,
% it is desirable that the models are as closely related from a theoretical and
% practical perspective as possible.
% Additionally, to test the hypothesis, it is required that both the artificial
% and spiking models can be simulated on regular machine architecture, while
% the spiking model requires a neuromorphic hardware platform.

% An optimal approach would be to find a tool that leverages the similarities
% of the network types, while integrating with the diverse simulated or emulated
% targets.
% That is, an abstract model of neural networks that can translate into
% heterogeneous back-ends, while retaining a high degree of inter-model validity.

% A number of general frameworks for artificial neural networks
% exist\footnote{
%   Among others, see \autocite{ONNX2018}, \autocite{PyTorch2018}, \autocite{TensorFlow2018},
%   \autocite{Keras2018} and DyNet \autocite{Neubig2017}.
% }, but none of them extend to the spiking domain.
% Conversely a number of choices exist for neuromorphic modelling\footnote{
%   %TODO: Find sources on internal IBM/Intel stuff
% }, but they exclusively evaluate to neuromorphic or spiking neural network
% backends \autocite{Jordan2018}.

\include{chapters/volr/volr}
\end{document}
